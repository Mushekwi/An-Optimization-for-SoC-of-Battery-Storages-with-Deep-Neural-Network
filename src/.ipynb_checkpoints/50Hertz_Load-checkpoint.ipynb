{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize some data files and see what we can do later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy.matlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50Hertz Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"../raw_data/load_data/50 Hertz Load\"\n",
    "filenames = os.listdir(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop 2015-2016-2017 because their format differs\n",
    "oldformat_filenames = filenames[:-3]\n",
    "newformat_filenames = filenames[-3:]\n",
    "# split actual and forecast files\n",
    "actual_filenames = [filename for filename in oldformat_filenames if 'actual' in filename]\n",
    "forecast_filenames = [filename for filename in oldformat_filenames if 'forecast' in filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new dataframe to ease preprocess.\n",
    "# This new dataframe should be time series\n",
    "\n",
    "def merge_actual_forecast(actual_df, forecast_df):\n",
    "    \"\"\"\n",
    "    Merges any two timeseries data. Dataframes should have 'data' column.\n",
    "    params: \n",
    "            actual_df: (pd.dataframe) any timeseries data\n",
    "            forecast_df: (pd.dataframe) any timeseries data\n",
    "    returns:\n",
    "            (pd.dataframe) merged dataframe\n",
    "    \"\"\"\n",
    "    actual_df['actual'] = actual_df['data']\n",
    "    actual_df['forecast'] = forecast_df['data']\n",
    "    actual_df.drop('data', axis=1, inplace=True)\n",
    "    return actual_df\n",
    "\n",
    "def extract_one_year(full_path):\n",
    "    \"\"\"\n",
    "    1.Reads ExcelFile. ExcelFile should have 'Info' and 'template' sheets, but we do not use them dont worry.\n",
    "        # todo: change 'Info' and 'template' necessity.\n",
    "    2. Calls extract_one_month function.\n",
    "    params: \n",
    "            full_path: (str)\n",
    "    returns:\n",
    "            (pd.dataframe) dataframe of one year.\n",
    "    \"\"\"\n",
    "    xls = pd.ExcelFile(full_path)\n",
    "    sheet_names = xls.sheet_names\n",
    "    sheet_names.remove('Info')\n",
    "    sheet_names.remove('template')\n",
    "    \n",
    "    one_year_df = pd.DataFrame()\n",
    "    for sheet_name in sheet_names:\n",
    "        one_year_df = one_year_df.append(extract_one_month(xls, sheet_name))\n",
    "    one_year_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return one_year_df\n",
    "\n",
    "def extract_one_month(xls, sheet_name):\n",
    "    \"\"\"\n",
    "    1.Parses xls.\n",
    "    2. Calls extract_one_day function.\n",
    "    params: \n",
    "            xls: (ExcelFile)\n",
    "            sheet_name: (str)\n",
    "    returns:\n",
    "            (pd.dataframe) dataframe of one month.\n",
    "    \"\"\"\n",
    "    raw_month_df = xls.parse(sheet_name, \n",
    "                             header=1, skiprows=1,index_col=False)\n",
    "    _dates = raw_month_df.columns.values[2:]\n",
    "    \n",
    "    one_month_df = pd.DataFrame()\n",
    "    for day_date in _dates:\n",
    "        one_day_df = extract_one_day(raw_month_df, day_date)    \n",
    "        one_month_df = one_month_df.append(one_day_df, ignore_index=True)\n",
    "    one_month_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return one_month_df\n",
    "\n",
    "def extract_one_day(raw_month_df, day_date):\n",
    "    \"\"\"\n",
    "    1. Remove 'b'and'a' chars from 'from'and 'to' columns.\n",
    "    2. Replace 'n.v.' with np.nan\n",
    "    params: \n",
    "            raw_month_df: (pd.Dataframe)\n",
    "            day_date: (datetime.datetime())\n",
    "    returns:\n",
    "            (pd.Dataframe) dataframe of one day. Pre_preprocess applied.\n",
    "    \"\"\"\n",
    "    \n",
    "    _from = raw_month_df['von'].values\n",
    "    _to = raw_month_df['bis'].values\n",
    "    day_sample_size = _from.shape[0]\n",
    "    \n",
    "    one_day_df = pd.DataFrame()\n",
    "    one_day_df['date'] = [day_date] * day_sample_size\n",
    "    one_day_df['from'] = _from\n",
    "    one_day_df['to']   = _to\n",
    "    one_day_df['data'] = raw_month_df.loc[:,day_date].values\n",
    "    \n",
    "    one_day_df = prepreprocess_day_dataframe(one_day_df)\n",
    "    return one_day_df\n",
    "\n",
    "def prepreprocess_day_dataframe(df):\n",
    "    def apply_each_quarter(row):\n",
    "        # what is 'b' and 'a'?\n",
    "#         print(row['from'],row['to'], row['date'])\n",
    "        row['from'] = row['from'].replace('a','')\n",
    "        row['to'] = row['to'].replace('a','')\n",
    "        \n",
    "\n",
    "        datetime_format = '%Y-%m-%d-%H:%M'\n",
    "        row['from'] = str(row['date'].date()) + '-' + row['from'] # add date into 'from'\n",
    "        row['from'] = pd.to_datetime(row['from'], format=datetime_format)\n",
    "        \n",
    "\n",
    "        if row['to'] == '24:00': # 24:00 is not an proper hour.\n",
    "            row['to'] = '00:00'\n",
    "            row['to'] = str(row['date'].date()) + '-' + row['to']\n",
    "            row['to'] = pd.to_datetime(row['to'])\n",
    "            row['to'] += pd.Timedelta(days=1)\n",
    "        else:\n",
    "            row['to'] = str(row['date'].date()) + '-' + row['to'] # add date into 'to'\n",
    "            row['to'] = pd.to_datetime(row['to'], format=datetime_format)\n",
    "               \n",
    "                   \n",
    "        \n",
    "        # change 'n.v.' with np.nan\n",
    "        row['data'] = np.nan if row['data'] == 'n.v.' else row['data']\n",
    "        \n",
    "        return row\n",
    "    df = df.apply(apply_each_quarter, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing old format files...\n",
      "Extracting 2010_actual.xls...\n",
      "Extracting 2010_forecast.xls...\n",
      "Extracting 2011_actual.xls...\n",
      "Extracting 2011_forecast.xls...\n",
      "Extracting 2012_actual.xls...\n",
      "Extracting 2012_forecast.xls...\n",
      "Extracting 2013_actual.xls...\n",
      "Extracting 2013_forecast.xls...\n",
      "Extracting 2014_actual.xls...\n",
      "Extracting 2014_forecast.xls...\n",
      "Processing new format files...\n",
      "Extracting 2015.csv...\n",
      "Extracting 2016.csv...\n",
      "Extracting 2017.csv...\n"
     ]
    }
   ],
   "source": [
    "# retrieve 2010-2011-2012-2013-2014\n",
    "print(\"Processing old format files...\")\n",
    "oldformat_dataframe = pd.DataFrame()\n",
    "for actual_filename, forecast_filename in zip(actual_filenames, forecast_filenames):\n",
    "    print(\"Extracting {}...\".format(actual_filename))\n",
    "    actual_year = extract_one_year(os.path.join(filepath, actual_filename))\n",
    "    print(\"Extracting {}...\".format(forecast_filename))\n",
    "    forecast_year = extract_one_year(os.path.join(filepath, forecast_filename))\n",
    "    oldformat_dataframe = oldformat_dataframe.append(merge_actual_forecast(actual_year, forecast_year))\n",
    "    \n",
    "oldformat_dataframe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# retrieve 2015-2016-2017\n",
    "print(\"Processing new format files...\")\n",
    "newformat_dataframe = pd.DataFrame()\n",
    "for filename in newformat_filenames:\n",
    "    print(\"Extracting {}...\".format(filename))\n",
    "    raw_data = pd.read_csv(os.path.join(filepath, filename))\n",
    "    raw_data.columns = ['date', 'forecast', 'actual']\n",
    "    # change dtype to datetime\n",
    "    raw_data['from'] = raw_data['date'].apply(lambda x: pd.to_datetime(x.split(' - ')[0], format='%d.%m.%Y %H:%M'))\n",
    "    raw_data['to']   = raw_data['date'].apply(lambda x: pd.to_datetime(x.split(' - ')[1], format='%d.%m.%Y %H:%M'))\n",
    "    raw_data['date'] = raw_data['date'].apply(lambda x: pd.to_datetime(x.split(' ')[0], format='%d.%m.%Y'))\n",
    "    \n",
    "    \n",
    "    raw_data = raw_data[['date','from','to','actual','forecast']]\n",
    "    newformat_dataframe = newformat_dataframe.append(raw_data)\n",
    "newformat_dataframe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# merge oldformat and newformat into one big file\n",
    "one_for_all_dataframe = oldformat_dataframe.append(newformat_dataframe)\n",
    "\n",
    "one_for_all_dataframe.to_csv(os.path.join(\"../input\",\"Load_50Hertz_2010-2017_cleaned.csv\"), index=None)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_one_year_df = extract_one_year(os.path.join(filepath,filenames[0]))\n",
    "forecast_one_year_xls = extract_one_year(os.path.join(filepath,filenames[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "XLRDError",
     "evalue": "No sheet named <'201401'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\xlrd\\book.py\u001b[0m in \u001b[0;36msheet_by_name\u001b[1;34m(self, sheet_name)\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m             \u001b[0msheetx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sheet_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: '201401' is not in list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e6ab9dd1b60e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mxls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mone_month\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_one_month\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'201401'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-e481be77eca7>\u001b[0m in \u001b[0;36mextract_one_month\u001b[1;34m(xls, sheet_name)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \"\"\"\n\u001b[0;32m     50\u001b[0m     raw_month_df = xls.parse(sheet_name, \n\u001b[1;32m---> 51\u001b[1;33m                              header=1, skiprows=1,index_col=False)\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0m_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_month_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, sheetname, header, skiprows, skip_footer, names, index_col, parse_cols, parse_dates, date_parser, na_values, thousands, convert_float, has_index_names, converters, true_values, false_values, squeeze, **kwds)\u001b[0m\n\u001b[0;32m    287\u001b[0m                                  \u001b[0mfalse_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfalse_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                                  \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                                  **kwds)\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_should_parse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m_parse_excel\u001b[1;34m(self, sheetname, header, skiprows, names, skip_footer, index_col, has_index_names, parse_cols, parse_dates, date_parser, na_values, thousands, convert_float, true_values, false_values, verbose, dtype, squeeze, **kwds)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[0msheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# assume an integer if not a string\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[0msheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_by_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\xlrd\\book.py\u001b[0m in \u001b[0;36msheet_by_name\u001b[1;34m(self, sheet_name)\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[0msheetx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sheet_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No sheet named <%r>'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_by_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msheetx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXLRDError\u001b[0m: No sheet named <'201401'>"
     ]
    }
   ],
   "source": [
    "xls = pd.ExcelFile(os.path.join(filepath,filenames[0]))\n",
    "one_month = extract_one_month(xls, '201401')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_year_df['actual'] = one_year_df['actual'].apply(lambda x: np.nan if x=='n.v.' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'13:30bb'.replace('b','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = pd.to_datetime('2014-01-01-00:15', format='%Y-%m-%d-%H:%M')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "t.day += datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('2921 days 00:00:00')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('2017-12-31')-pd.to_datetime('2010-01-01')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280512"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2922*24*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>actual</th>\n",
       "      <th>forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010-01-01 00:15:00</td>\n",
       "      <td>6382.0</td>\n",
       "      <td>7275.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date       from                   to  actual  forecast\n",
       "0  2010-01-01 00:00:00 2010-01-01  2010-01-01 00:15:00  6382.0    7275.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = pd.read_csv('../input/Load_50Hertz_2010-2017_cleaned.csv')\n",
    "h['from'] = h['from'].apply(lambda x: pd.to_datetime(x))\n",
    "h.loc[(h['from'].diff(1) != pd.Timedelta(minutes=15))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>actual</th>\n",
       "      <th>forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203810</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 00:30:00</td>\n",
       "      <td>2015-10-25 00:45:00</td>\n",
       "      <td>6983.0</td>\n",
       "      <td>5943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203811</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 00:45:00</td>\n",
       "      <td>2015-10-25 01:00:00</td>\n",
       "      <td>6789.0</td>\n",
       "      <td>5861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203812</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 01:00:00</td>\n",
       "      <td>2015-10-25 01:15:00</td>\n",
       "      <td>6789.0</td>\n",
       "      <td>5800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203813</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 01:15:00</td>\n",
       "      <td>2015-10-25 01:30:00</td>\n",
       "      <td>6606.0</td>\n",
       "      <td>5744.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203814</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 01:30:00</td>\n",
       "      <td>2015-10-25 01:45:00</td>\n",
       "      <td>6634.0</td>\n",
       "      <td>5691.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203815</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 01:45:00</td>\n",
       "      <td>2015-10-25 02:00:00</td>\n",
       "      <td>6521.0</td>\n",
       "      <td>5654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203816</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 02:00:00</td>\n",
       "      <td>2015-10-25 02:15:00</td>\n",
       "      <td>6337.0</td>\n",
       "      <td>5610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203817</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 02:15:00</td>\n",
       "      <td>2015-10-25 02:30:00</td>\n",
       "      <td>6369.0</td>\n",
       "      <td>5568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203818</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 02:30:00</td>\n",
       "      <td>2015-10-25 02:45:00</td>\n",
       "      <td>6440.0</td>\n",
       "      <td>5538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203819</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 02:45:00</td>\n",
       "      <td>2015-10-25 03:00:00</td>\n",
       "      <td>6387.0</td>\n",
       "      <td>5529.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203820</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 02:00:00</td>\n",
       "      <td>2015-10-25 02:15:00</td>\n",
       "      <td>6334.0</td>\n",
       "      <td>5526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203821</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 02:15:00</td>\n",
       "      <td>2015-10-25 02:30:00</td>\n",
       "      <td>6298.0</td>\n",
       "      <td>5525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203822</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 02:30:00</td>\n",
       "      <td>2015-10-25 02:45:00</td>\n",
       "      <td>6449.0</td>\n",
       "      <td>5527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203823</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 02:45:00</td>\n",
       "      <td>2015-10-25 03:00:00</td>\n",
       "      <td>6466.0</td>\n",
       "      <td>5534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203824</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 03:00:00</td>\n",
       "      <td>2015-10-25 03:15:00</td>\n",
       "      <td>6282.0</td>\n",
       "      <td>5537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203825</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 03:15:00</td>\n",
       "      <td>2015-10-25 03:30:00</td>\n",
       "      <td>6266.0</td>\n",
       "      <td>5510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203826</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 03:30:00</td>\n",
       "      <td>2015-10-25 03:45:00</td>\n",
       "      <td>6457.0</td>\n",
       "      <td>5535.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203827</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 03:45:00</td>\n",
       "      <td>2015-10-25 04:00:00</td>\n",
       "      <td>6418.0</td>\n",
       "      <td>5506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203828</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 04:00:00</td>\n",
       "      <td>2015-10-25 04:15:00</td>\n",
       "      <td>6420.0</td>\n",
       "      <td>5581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203829</th>\n",
       "      <td>2015-10-25 00:00:00</td>\n",
       "      <td>2015-10-25 04:15:00</td>\n",
       "      <td>2015-10-25 04:30:00</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>5589.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date                from                   to  actual  \\\n",
       "203810  2015-10-25 00:00:00 2015-10-25 00:30:00  2015-10-25 00:45:00  6983.0   \n",
       "203811  2015-10-25 00:00:00 2015-10-25 00:45:00  2015-10-25 01:00:00  6789.0   \n",
       "203812  2015-10-25 00:00:00 2015-10-25 01:00:00  2015-10-25 01:15:00  6789.0   \n",
       "203813  2015-10-25 00:00:00 2015-10-25 01:15:00  2015-10-25 01:30:00  6606.0   \n",
       "203814  2015-10-25 00:00:00 2015-10-25 01:30:00  2015-10-25 01:45:00  6634.0   \n",
       "203815  2015-10-25 00:00:00 2015-10-25 01:45:00  2015-10-25 02:00:00  6521.0   \n",
       "203816  2015-10-25 00:00:00 2015-10-25 02:00:00  2015-10-25 02:15:00  6337.0   \n",
       "203817  2015-10-25 00:00:00 2015-10-25 02:15:00  2015-10-25 02:30:00  6369.0   \n",
       "203818  2015-10-25 00:00:00 2015-10-25 02:30:00  2015-10-25 02:45:00  6440.0   \n",
       "203819  2015-10-25 00:00:00 2015-10-25 02:45:00  2015-10-25 03:00:00  6387.0   \n",
       "203820  2015-10-25 00:00:00 2015-10-25 02:00:00  2015-10-25 02:15:00  6334.0   \n",
       "203821  2015-10-25 00:00:00 2015-10-25 02:15:00  2015-10-25 02:30:00  6298.0   \n",
       "203822  2015-10-25 00:00:00 2015-10-25 02:30:00  2015-10-25 02:45:00  6449.0   \n",
       "203823  2015-10-25 00:00:00 2015-10-25 02:45:00  2015-10-25 03:00:00  6466.0   \n",
       "203824  2015-10-25 00:00:00 2015-10-25 03:00:00  2015-10-25 03:15:00  6282.0   \n",
       "203825  2015-10-25 00:00:00 2015-10-25 03:15:00  2015-10-25 03:30:00  6266.0   \n",
       "203826  2015-10-25 00:00:00 2015-10-25 03:30:00  2015-10-25 03:45:00  6457.0   \n",
       "203827  2015-10-25 00:00:00 2015-10-25 03:45:00  2015-10-25 04:00:00  6418.0   \n",
       "203828  2015-10-25 00:00:00 2015-10-25 04:00:00  2015-10-25 04:15:00  6420.0   \n",
       "203829  2015-10-25 00:00:00 2015-10-25 04:15:00  2015-10-25 04:30:00  6240.0   \n",
       "\n",
       "        forecast  \n",
       "203810    5943.0  \n",
       "203811    5861.0  \n",
       "203812    5800.0  \n",
       "203813    5744.0  \n",
       "203814    5691.0  \n",
       "203815    5654.0  \n",
       "203816    5610.0  \n",
       "203817    5568.0  \n",
       "203818    5538.0  \n",
       "203819    5529.0  \n",
       "203820    5526.0  \n",
       "203821    5525.0  \n",
       "203822    5527.0  \n",
       "203823    5534.0  \n",
       "203824    5537.0  \n",
       "203825    5510.0  \n",
       "203826    5535.0  \n",
       "203827    5506.0  \n",
       "203828    5581.0  \n",
       "203829    5589.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.iloc[203810:203830]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280524, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_for_all_dataframe.plot(['actual','forecast'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
