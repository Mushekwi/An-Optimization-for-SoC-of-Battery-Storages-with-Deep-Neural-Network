{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets visualize some data files and see what we can do later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy.matlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50Hertz Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"../raw_data/load_data/50 Hertz Load\"\n",
    "filenames = os.listdir(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 2015-2016-2017 because their format differs\n",
    "oldformat_filenames = filenames[:-3]\n",
    "newformat_filenames = filenames[-3:]\n",
    "# split actual and forecast files\n",
    "actual_filenames = [filename for filename in oldformat_filenames if 'actual' in filename]\n",
    "forecast_filenames = [filename for filename in oldformat_filenames if 'forecast' in filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing old format files...\n",
      "Extracting 2010_actual.xls...\n",
      "Extracting 2010_forecast.xls...\n",
      "Extracting 2011_actual.xls...\n",
      "Extracting 2011_forecast.xls...\n",
      "Extracting 2012_actual.xls...\n",
      "Extracting 2012_forecast.xls...\n",
      "Extracting 2013_actual.xls...\n",
      "Extracting 2013_forecast.xls...\n",
      "Extracting 2014_actual.xls...\n",
      "Extracting 2014_forecast.xls...\n",
      "Processing new format files...\n",
      "Extracting 2015.csv...\n",
      "Extracting 2016.csv...\n",
      "Extracting 2017.csv...\n"
     ]
    }
   ],
   "source": [
    "# retrieve 2010-2011-2012-2013-2014\n",
    "print(\"Processing old format files...\")\n",
    "oldformat_dataframe = pd.DataFrame()\n",
    "for actual_filename, forecast_filename in zip(actual_filenames, forecast_filenames):\n",
    "    print(\"Extracting {}...\".format(actual_filename))\n",
    "    actual_year = extract_one_year(os.path.join(filepath, actual_filename))\n",
    "    print(\"Extracting {}...\".format(forecast_filename))\n",
    "    forecast_year = extract_one_year(os.path.join(filepath, forecast_filename))\n",
    "    oldformat_dataframe = oldformat_dataframe.append(merge_actual_forecast(actual_year, forecast_year))\n",
    "    \n",
    "oldformat_dataframe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# retrieve 2015-2016-2017\n",
    "print(\"Processing new format files...\")\n",
    "newformat_dataframe = pd.DataFrame()\n",
    "for filename in newformat_filenames:\n",
    "    print(\"Extracting {}...\".format(filename))\n",
    "    raw_data = pd.read_csv(os.path.join(filepath, filename))\n",
    "    raw_data.columns = ['date', 'forecast', 'actual']\n",
    "    raw_data['from'] = raw_data['date'].apply(lambda x: pd.to_datetime(x.split('-')[0]))\n",
    "    raw_data['to']   = raw_data['date'].apply(lambda x: pd.to_datetime(x.split('-')[1]))\n",
    "    raw_data['date'] = raw_data['date'].apply(lambda x: pd.to_datetime(x.split(' ')[0]))\n",
    "    raw_data = raw_data[['date','from','to','actual','forecast']]\n",
    "    newformat_dataframe = newformat_dataframe.append(raw_data)\n",
    "newformat_dataframe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# merge oldformat and newformat into one big file\n",
    "one_for_all_dataframe = oldformat_dataframe.append(newformat_dataframe)\n",
    "\n",
    "one_for_all_dataframe.to_csv(os.path.join(\"../input\",\"Load_50Hertz_2010-2017_cleaned.csv\"), index=None)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe to ease preprocess.\n",
    "# This new dataframe should be time series\n",
    "\n",
    "def merge_actual_forecast(actual_df, forecast_df):\n",
    "    \"\"\"\n",
    "    Merges any two timeseries data. Dataframes should have 'data' column.\n",
    "    params: \n",
    "            actual_df: (pd.dataframe) any timeseries data\n",
    "            forecast_df: (pd.dataframe) any timeseries data\n",
    "    returns:\n",
    "            (pd.dataframe) merged dataframe\n",
    "    \"\"\"\n",
    "    actual_df['actual'] = actual_df['data']\n",
    "    actual_df['forecast'] = forecast_df['data']\n",
    "    actual_df.drop('data', axis=1, inplace=True)\n",
    "    return actual_df\n",
    "\n",
    "def extract_one_year(full_path):\n",
    "    \"\"\"\n",
    "    1.Reads ExcelFile. ExcelFile should have 'Info' and 'template' sheets, but we do not use them dont worry.\n",
    "        # todo: change 'Info' and 'template' necessity.\n",
    "    2. Calls extract_one_month function.\n",
    "    params: \n",
    "            full_path: (str)\n",
    "    returns:\n",
    "            (pd.dataframe) dataframe of one year.\n",
    "    \"\"\"\n",
    "    xls = pd.ExcelFile(full_path)\n",
    "    sheet_names = xls.sheet_names\n",
    "    sheet_names.remove('Info')\n",
    "    sheet_names.remove('template')\n",
    "    \n",
    "    one_year_df = pd.DataFrame()\n",
    "    for sheet_name in sheet_names:\n",
    "        one_year_df = one_year_df.append(extract_one_month(xls, sheet_name))\n",
    "    one_year_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return one_year_df\n",
    "\n",
    "def extract_one_month(xls, sheet_name):\n",
    "    \"\"\"\n",
    "    1.Parses xls.\n",
    "    2. Calls extract_one_day function.\n",
    "    params: \n",
    "            xls: (ExcelFile)\n",
    "            sheet_name: (str)\n",
    "    returns:\n",
    "            (pd.dataframe) dataframe of one month.\n",
    "    \"\"\"\n",
    "    raw_month_df = xls.parse(sheet_name, \n",
    "                             header=1, skiprows=1,index_col=False)\n",
    "    _dates = raw_month_df.columns.values[2:]\n",
    "    \n",
    "    one_month_df = pd.DataFrame()\n",
    "    for day_date in _dates:\n",
    "        one_day_df = extract_one_day(raw_month_df, day_date)    \n",
    "        one_month_df = one_month_df.append(one_day_df, ignore_index=True)\n",
    "    one_month_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return one_month_df\n",
    "\n",
    "def extract_one_day(raw_month_df, day_date):\n",
    "    \"\"\"\n",
    "    1. Remove 'b'and'a' chars from 'from'and 'to' columns.\n",
    "    2. Replace 'n.v.' with np.nan\n",
    "    params: \n",
    "            raw_month_df: (pd.Dataframe)\n",
    "            day_date: (datetime.datetime())\n",
    "    returns:\n",
    "            (pd.Dataframe) dataframe of one day. Pre_preprocess applied.\n",
    "    \"\"\"\n",
    "    \n",
    "    _from = raw_month_df['von'].values\n",
    "    _to = raw_month_df['bis'].values\n",
    "    day_sample_size = _from.shape[0]\n",
    "    \n",
    "    one_day_df = pd.DataFrame()\n",
    "    one_day_df['date'] = [day_date] * day_sample_size\n",
    "    one_day_df['from'] = _from\n",
    "    one_day_df['to']   = _to\n",
    "    one_day_df['data'] = raw_month_df.loc[:,day_date].values\n",
    "    \n",
    "    one_day_df = prepreprocess_day_dataframe(one_day_df)\n",
    "    return one_day_df\n",
    "\n",
    "def prepreprocess_day_dataframe(df):\n",
    "    def apply_each_quarter(row):\n",
    "        # what is 'b' and 'a'?\n",
    "        row['from'] = row['from'].replace('b','')\n",
    "        row['to'] = row['to'].replace('b','')\n",
    "        row['from'] = row['from'].replace('a','')\n",
    "        row['to'] = row['to'].replace('a','')\n",
    "        \n",
    "\n",
    "        datetime_format = '%Y-%m-%d-%H:%M'\n",
    "        row['from'] = str(row['date'].date()) + '-' + row['from'] # add date into 'from'\n",
    "        row['from'] = pd.to_datetime(row['from'], format=datetime_format)\n",
    "        \n",
    "\n",
    "        if row['to'] == '24:00': # 24:00 is not an proper hour.\n",
    "            row['to'] = '00:00'\n",
    "            row['to'] = str(row['date'].date()) + '-' + row['to']\n",
    "            row['to'] = pd.to_datetime(row['to'])\n",
    "            row['to'] += pd.Timedelta(days=1)\n",
    "        else:\n",
    "            row['to'] = str(row['date'].date()) + '-' + row['to'] # add date into 'to'\n",
    "            row['to'] = pd.to_datetime(row['to'], format=datetime_format)\n",
    "               \n",
    "                   \n",
    "        \n",
    "        # change 'n.v.' with np.nan\n",
    "        row['data'] = np.nan if row['data'] == 'n.v.' else row['data']\n",
    "        \n",
    "        return row\n",
    "    df = df.apply(apply_each_quarter, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_one_year_df = extract_one_year(os.path.join(filepath,filenames[0]))\n",
    "forecast_one_year_xls = extract_one_year(os.path.join(filepath,filenames[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile(os.path.join(filepath,filenames[0]))\n",
    "one_month = extract_one_month(xls, '201401')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_df['actual'] = one_year_df['actual'].apply(lambda x: np.nan if x=='n.v.' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'13:30bb'.replace('b','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.to_datetime('2014-01-01-00:15', format='%Y-%m-%d-%H:%M')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "t.day += datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.to_datetime('2014-01-31 00:00:00-00:00')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t += pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_for_all_dataframe.plot(['actual','forecast'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
